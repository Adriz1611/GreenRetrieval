{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9CxQlZNopLE"
      },
      "source": [
        "# üåø GreenRetrieval ‚Äì AI Plant Disease Diagnosis\n",
        "\n",
        "**Complete, self-contained Google Colab notebook** for diagnosing plant diseases using:\n",
        "- **EPPO Global Database** for verified plant pathogen data  \n",
        "- **Groq LLM** for natural language generation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## üìã What You Need\n",
        "\n",
        "### 1. API Keys (both free):\n",
        "- **EPPO API Key**: Get from https://data.eppo.int  \n",
        "- **Groq API Key**: Get from https://console.groq.com/keys\n",
        "\n",
        "### 2. SQLite Database:\n",
        "- Download **`eppocodes_all.sqlite`** from https://www.eppo.int/download  \n",
        "- Upload it to Colab (see Step 2 below)\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "1. **Upload Database** ‚Üí Use the folder icon (üìÅ) in left sidebar to upload `eppocodes_all.sqlite` to `/content/`\n",
        "2. **Install Dependencies** ‚Üí Run the cell below\n",
        "3. **Set API Keys** ‚Üí Paste your keys in the configuration cell  \n",
        "4. **Run Diagnoses!** ‚Üí Execute the final cell\n",
        "\n",
        "Let's go! üëá"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ypCpa4MopLF"
      },
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtn1xKjoopLF",
        "outputId": "eeb844b9-4f64-4b82-911f-7b0887de5245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/138.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.7/138.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q groq requests tqdm\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcZ7ZV24opLG"
      },
      "source": [
        "## Step 2: Load SQLite Database\n",
        "\n",
        "**Choose ONE of the two methods below:**\n",
        "\n",
        "### üîπ Method 1: Upload Directly (Temporary - lost when runtime restarts)\n",
        "### üîπ Method 2: Connect to Google Drive (Persistent - survives runtime restarts)\n",
        "\n",
        "Run the cell below and follow the prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZahYFvgiopLH",
        "outputId": "a6d7eb18-a7b9-4b6b-a26c-7013c0fb59c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üóÑÔ∏è  DATABASE SETUP\n",
            "============================================================\n",
            "Choose how to load the SQLite database:\n",
            "\n",
            "1Ô∏è‚É£  Upload directly (temporary - lost on runtime restart)\n",
            "2Ô∏è‚É£  Load from Google Drive (persistent)\n",
            "\n",
            "Enter your choice (1 or 2): 2\n",
            "\n",
            "üìÇ Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "\n",
            "üìç Enter the path to your database in Google Drive\n",
            "   Example: /content/drive/MyDrive/datasets/eppocodes_all.sqlite\n",
            "   Or just: MyDrive/datasets/eppocodes_all.sqlite\n",
            "\n",
            "Path: /content/drive/MyDrive/greenretrieval/eppocodes_all.sqlite\n",
            "‚úÖ Database linked from Google Drive\n",
            "\n",
            "============================================================\n",
            "‚úÖ Database ready!\n",
            "   Location: /content/eppocodes_all.sqlite\n",
            "   Size: 47.3 MB\n"
          ]
        }
      ],
      "source": [
        "# Load SQLite Database - Choose your method\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "print(\"üóÑÔ∏è  DATABASE SETUP\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Choose how to load the SQLite database:\\n\")\n",
        "print(\"1Ô∏è‚É£  Upload directly (temporary - lost on runtime restart)\")\n",
        "print(\"2Ô∏è‚É£  Load from Google Drive (persistent)\\n\")\n",
        "\n",
        "choice = input(\"Enter your choice (1 or 2): \").strip()\n",
        "\n",
        "DB_PATH = Path(\"/content/eppocodes_all.sqlite\")\n",
        "\n",
        "if choice == \"1\":\n",
        "    # Method 1: Direct Upload\n",
        "    print(\"\\nüì§ Upload eppocodes_all.sqlite using the file picker...\")\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if 'eppocodes_all.sqlite' in uploaded:\n",
        "        # Move to expected location\n",
        "        import shutil\n",
        "        if Path('eppocodes_all.sqlite').exists():\n",
        "            shutil.move('eppocodes_all.sqlite', str(DB_PATH))\n",
        "        print(f\"‚úÖ Database uploaded to {DB_PATH}\")\n",
        "    else:\n",
        "        print(\"‚ùå Error: Please upload a file named 'eppocodes_all.sqlite'\")\n",
        "\n",
        "elif choice == \"2\":\n",
        "    # Method 2: Google Drive\n",
        "    print(\"\\nüìÇ Mounting Google Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    print(\"\\nüìç Enter the path to your database in Google Drive\")\n",
        "    print(\"   Example: /content/drive/MyDrive/datasets/eppocodes_all.sqlite\")\n",
        "    print(\"   Or just: MyDrive/datasets/eppocodes_all.sqlite\\n\")\n",
        "\n",
        "    gdrive_path = input(\"Path: \").strip()\n",
        "\n",
        "    # Handle both absolute and relative paths\n",
        "    if not gdrive_path.startswith('/content/drive/'):\n",
        "        gdrive_path = f\"/content/drive/{gdrive_path}\"\n",
        "\n",
        "    source_path = Path(gdrive_path)\n",
        "\n",
        "    if source_path.exists():\n",
        "        # Create symlink for consistent access\n",
        "        if DB_PATH.exists():\n",
        "            DB_PATH.unlink()\n",
        "        DB_PATH.symlink_to(source_path)\n",
        "        print(f\"‚úÖ Database linked from Google Drive\")\n",
        "    else:\n",
        "        print(f\"‚ùå Error: Database not found at {source_path}\")\n",
        "        print(\"   Make sure you've uploaded eppocodes_all.sqlite to Google Drive\")\n",
        "        print(\"   and the path is correct.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Invalid choice. Please run the cell again and enter 1 or 2.\")\n",
        "\n",
        "# Verify database\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "if DB_PATH.exists():\n",
        "    size_mb = DB_PATH.stat().st_size / (1024 * 1024)\n",
        "    print(f\"‚úÖ Database ready!\")\n",
        "    print(f\"   Location: {DB_PATH}\")\n",
        "    print(f\"   Size: {size_mb:.1f} MB\")\n",
        "\n",
        "    # Update environment variable\n",
        "    os.environ[\"EPPO_SQLITE_PATH\"] = str(DB_PATH)\n",
        "else:\n",
        "    print(\"‚ùå Database not found. Please try again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk0oNjafopLH"
      },
      "source": [
        "## Step 3: Set Your API Keys (Using Colab Secrets) üîê\n",
        "\n",
        "**For security, use Google Colab's Secrets feature:**\n",
        "\n",
        "1. Click the **üîë key icon** in the left sidebar (Secrets)\n",
        "2. Add two secrets:\n",
        "   - Name: `EPPO_API_KEY` ‚Üí Value: Your EPPO API key\n",
        "   - Name: `GROQ_API_KEY` ‚Üí Value: Your Groq API key\n",
        "3. **Enable notebook access** by toggling the switch for each secret\n",
        "4. Run the cell below to load them\n",
        "\n",
        "**Alternative:** If you prefer, you can manually set them by uncommenting the manual method in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZWidl8JopLH",
        "outputId": "0fd29649-45cc-4ac9-b7ab-db782e43e4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded API keys from Colab Secrets!\n",
            "‚úÖ API keys configured!\n",
            "   EPPO: ****************************5b35\n",
            "   Groq: ****************************************************tO6E\n"
          ]
        }
      ],
      "source": [
        "# Configuration: Load API keys from Colab Secrets\n",
        "import os\n",
        "\n",
        "# Method 1: Using Google Colab Secrets (RECOMMENDED - Secure)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"EPPO_API_KEY\"] = userdata.get('EPPO_API_KEY')\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "    print(\"‚úÖ Loaded API keys from Colab Secrets!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è  Could not load from Colab Secrets. Using manual method...\")\n",
        "    print(f\"   Error: {e}\")\n",
        "\n",
        "    # Method 2: Manual (NOT RECOMMENDED - Keys visible in code)\n",
        "    # Uncomment and paste your keys here if Secrets don't work:\n",
        "    # os.environ[\"EPPO_API_KEY\"] = \"\"  # üëà Paste your EPPO key here\n",
        "    # os.environ[\"GROQ_API_KEY\"] = \"\"  # üëà Paste your Groq key here\n",
        "\n",
        "# Paths\n",
        "os.environ[\"EPPO_SQLITE_PATH\"] = \"/content/eppocodes_all.sqlite\"\n",
        "os.environ[\"EPPO_CACHE_DIR\"] = \"/content/.eppo_cache\"\n",
        "\n",
        "# Verify keys are set\n",
        "eppo_key = os.environ.get(\"EPPO_API_KEY\", \"\")\n",
        "groq_key = os.environ.get(\"GROQ_API_KEY\", \"\")\n",
        "\n",
        "if eppo_key and groq_key:\n",
        "    print(\"‚úÖ API keys configured!\")\n",
        "    print(f\"   EPPO: {'*' * (len(eppo_key) - 4)}{eppo_key[-4:]}\")\n",
        "    print(f\"   Groq: {'*' * (len(groq_key) - 4)}{groq_key[-4:]}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Warning: One or both API keys are missing\")\n",
        "    if not eppo_key:\n",
        "        print(\"  ‚ùå EPPO_API_KEY not set\")\n",
        "    if not groq_key:\n",
        "        print(\"  ‚ùå GROQ_API_KEY not set\")\n",
        "    print(\"\\nüìå To fix this:\")\n",
        "    print(\"   1. Click the üîë key icon in the left sidebar\")\n",
        "    print(\"   2. Add secrets: EPPO_API_KEY and GROQ_API_KEY\")\n",
        "    print(\"   3. Enable 'Notebook access' for both\")\n",
        "    print(\"   4. Re-run this cell\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLKCEU-6opLH"
      },
      "source": [
        "## Step 4: Load All Code (One Cell!)\n",
        "\n",
        "This cell contains the entire GreenRetrieval pipeline. Just run it once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFJf6FMOopLH",
        "outputId": "43d3d68f-08e8-4c99-df87-3dbcd0eb0c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GreenRetrieval pipeline loaded successfully!\n",
            "üìä Configuration: Confidence threshold = 0.3, Model = openai/gpt-oss-120b\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# GreenRetrieval ‚Äì Complete Pipeline (Self-Contained)\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Set, Tuple\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Global Statistics Tracking\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "class PipelineStats:\n",
        "    def __init__(self):\n",
        "        self.cache_hits = 0\n",
        "        self.cache_misses = 0\n",
        "        self.api_calls = 0\n",
        "        self.groq_calls = 0\n",
        "        self.diagnoses = []\n",
        "\n",
        "    def reset(self):\n",
        "        self.cache_hits = 0\n",
        "        self.cache_misses = 0\n",
        "        self.api_calls = 0\n",
        "        self.groq_calls = 0\n",
        "        self.diagnoses = []\n",
        "\n",
        "    def add_diagnosis(self, result, label):\n",
        "        self.diagnoses.append({\"label\": label, \"result\": result})\n",
        "\n",
        "    def summary(self):\n",
        "        total = len(self.diagnoses)\n",
        "        if total == 0:\n",
        "            return \"No diagnoses performed.\"\n",
        "\n",
        "        verified = sum(1 for d in self.diagnoses if not d[\"result\"].refused)\n",
        "        refused = total - verified\n",
        "        avg_conf = sum(d[\"result\"].confidence or 0 for d in self.diagnoses if d[\"result\"].confidence) / total\n",
        "\n",
        "        lines = [\n",
        "            \"\\n\" + \"=\" * 80,\n",
        "            \"üìä PIPELINE SUMMARY STATISTICS\",\n",
        "            \"=\" * 80,\n",
        "            f\"‚úÖ Verified: {verified}/{total} ({verified/total*100:.1f}%)\",\n",
        "            f\"üö´ Refused: {refused}/{total} ({refused/total*100:.1f}%)\",\n",
        "            f\"üéØ Average Confidence: {avg_conf:.2%}\",\n",
        "            f\"\\nüíæ EPPO API Cache:\",\n",
        "            f\"   Hits: {self.cache_hits} (reused from disk)\",\n",
        "            f\"   Misses: {self.cache_misses} (fetched from API)\",\n",
        "            f\"   Total API Calls: {self.api_calls}\",\n",
        "            f\"\\nü§ñ Groq LLM Calls: {self.groq_calls}\",\n",
        "            \"=\" * 80,\n",
        "        ]\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "STATS = PipelineStats()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content\")\n",
        "SQLITE_PATH = Path(os.environ.get(\"EPPO_SQLITE_PATH\", \"/content/eppocodes_all.sqlite\"))\n",
        "EPPO_CACHE_DIR = Path(os.environ.get(\"EPPO_CACHE_DIR\", \"/content/.eppo_cache\"))\n",
        "\n",
        "EPPO_API_KEY = os.environ.get(\"EPPO_API_KEY\", \"\")\n",
        "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"\")\n",
        "\n",
        "EPPO_BASE_URL = \"https://api.eppo.int/gd/v2\"\n",
        "CONFIDENCE_THRESHOLD = 0.3  # Lowered from 0.45 for better recall\n",
        "GROQ_MODEL = \"openai/gpt-oss-120b\"  # 120B model for best accuracy + built-in search\n",
        "GROQ_MAX_TOKENS = 1024\n",
        "GROQ_TEMPERATURE = 0.3  # Low temp = more factual, less creative\n",
        "EPPO_RATE_LIMIT_DELAY = 0.2\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1. Normalization\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "GENERIC_TERMS = frozenset({\n",
        "    \"of\", \"the\", \"and\", \"on\", \"in\", \"plant\", \"plants\", \"crop\", \"crops\",\n",
        "})\n",
        "LOCATION_TERMS = frozenset({\n",
        "    \"leaf\", \"leaves\", \"stem\", \"stems\", \"fruit\", \"fruits\", \"root\", \"roots\",\n",
        "    \"seed\", \"seeds\", \"flower\", \"flowers\", \"bark\", \"shoot\", \"branch\",\n",
        "})\n",
        "# Symptom synonyms for better semantic matching\n",
        "SYMPTOM_SYNONYMS = {\n",
        "    \"blight\": {\"blight\", \"spot\", \"lesion\", \"necrosis\"},\n",
        "    \"rust\": {\"rust\", \"uredinia\", \"pustule\"},\n",
        "    \"mosaic\": {\"mosaic\", \"mottle\", \"pattern\", \"variegation\"},\n",
        "    \"rot\": {\"rot\", \"decay\", \"decomposition\"},\n",
        "    \"wilt\": {\"wilt\", \"wilting\", \"droop\", \"collapse\"},\n",
        "    \"curl\": {\"curl\", \"curling\", \"distortion\", \"deformation\"},\n",
        "}\n",
        "MIN_TOKEN_LEN = 2\n",
        "\n",
        "@dataclass\n",
        "class NormalizedLabel:\n",
        "    original: str\n",
        "    tokens: List[str]\n",
        "    host_candidates: List[str]\n",
        "    symptom_candidates: List[str]\n",
        "    location_terms: List[str]  # NEW: preserve location keywords\n",
        "\n",
        "def _tokenize(text: str) -> List[str]:\n",
        "    text = (text or \"\").strip().lower()\n",
        "    tokens = re.split(r\"[^\\w]+\", text)\n",
        "    return [t for t in tokens if len(t) >= MIN_TOKEN_LEN]\n",
        "\n",
        "def normalize_cv_label(label: str) -> NormalizedLabel:\n",
        "    if not (label or isinstance(label, str)):\n",
        "        return NormalizedLabel(original=label or \"\", tokens=[], host_candidates=[],\n",
        "                                symptom_candidates=[], location_terms=[])\n",
        "\n",
        "    original = label.strip()\n",
        "    tokens = _tokenize(original)\n",
        "\n",
        "    # Extract location terms BEFORE filtering\n",
        "    location_terms = [t for t in tokens if t in LOCATION_TERMS]\n",
        "\n",
        "    # Filter out generic terms but keep location terms\n",
        "    meaningful = [t for t in tokens if t not in GENERIC_TERMS]\n",
        "\n",
        "    if not meaningful:\n",
        "        meaningful = tokens\n",
        "\n",
        "    host_candidates = [meaningful[0]] if meaningful else []\n",
        "    symptom_candidates = meaningful[1:] if len(meaningful) > 1 else meaningful\n",
        "\n",
        "    return NormalizedLabel(\n",
        "        original=original,\n",
        "        tokens=meaningful,\n",
        "        host_candidates=host_candidates,\n",
        "        symptom_candidates=symptom_candidates,\n",
        "        location_terms=location_terms,\n",
        "    )\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2. Retrieval\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "PREFERRED_DTCODE = \"GAF\"\n",
        "SECONDARY_DTCODES = frozenset({\"SFT\"})\n",
        "\n",
        "@dataclass\n",
        "class Candidate:\n",
        "    eppocode: str\n",
        "    dtcode: str\n",
        "    fullname: str\n",
        "    score: float\n",
        "    token_overlap: int\n",
        "    host_match: bool\n",
        "\n",
        "def _tokenize_name(name: str) -> set:\n",
        "    tokens = re.split(r\"[^\\w]+\", (name or \"\").lower())\n",
        "    return {t for t in tokens if len(t) >= 2}\n",
        "\n",
        "def _score_candidate(eppocode: str, dtcode: str, fullname: str, norm: NormalizedLabel) -> Tuple[float, int, bool]:\n",
        "    name_tokens = _tokenize_name(fullname)\n",
        "    query_tokens = set(norm.tokens)\n",
        "    overlap = len(query_tokens & name_tokens)\n",
        "    host_match = bool(norm.host_candidates and (set(norm.host_candidates) & name_tokens))\n",
        "\n",
        "    # NEW: Check if location terms match (e.g., \"leaf rust\" should match names with \"leaf\")\n",
        "    location_match = 0\n",
        "    if norm.location_terms:\n",
        "        location_tokens = set(norm.location_terms)\n",
        "        location_match = len(location_tokens & name_tokens) / len(location_tokens)\n",
        "\n",
        "    query_len = max(len(query_tokens), 1)\n",
        "    overlap_ratio = overlap / query_len\n",
        "    host_bonus = 0.2 if host_match else 0.0\n",
        "    location_bonus = 0.3 * location_match  # NEW: Strong bonus for matching location terms\n",
        "    dtcode_bonus = 0.15 if dtcode == PREFERRED_DTCODE else (0.05 if dtcode in SECONDARY_DTCODES else 0.0)\n",
        "\n",
        "    score = overlap_ratio + host_bonus + location_bonus + dtcode_bonus\n",
        "    return (min(score, 1.5), overlap, host_match)  # Allow scores > 1.0 for better differentiation\n",
        "\n",
        "def query_candidates(sqlite_path: Path, norm: NormalizedLabel, max_candidates: int = 50) -> List[Candidate]:\n",
        "    if not norm.tokens or not sqlite_path.exists():\n",
        "        return []\n",
        "\n",
        "    conn = sqlite3.connect(str(sqlite_path))\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    try:\n",
        "        placeholders = \" OR \".join([\"n.fullname LIKE ?\" for _ in norm.tokens])\n",
        "        params = [f\"%{t}%\" for t in norm.tokens]\n",
        "\n",
        "        sql = f\"\"\"\n",
        "            SELECT DISTINCT c.eppocode, c.dtcode, n.fullname\n",
        "            FROM t_codes c\n",
        "            JOIN t_names n ON c.codeid = n.codeid\n",
        "            WHERE c.status = 'A' AND n.status = 'A'\n",
        "              AND ({placeholders})\n",
        "        \"\"\"\n",
        "        cur = conn.execute(sql, params)\n",
        "        rows = list(cur.fetchall())\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "    query_tokens_set = set(norm.tokens)\n",
        "    by_code: dict[Tuple[str, str], str] = {}\n",
        "    for row in rows:\n",
        "        key = (row[\"eppocode\"], row[\"dtcode\"])\n",
        "        name = row[\"fullname\"] or \"\"\n",
        "        name_tokens = _tokenize_name(name)\n",
        "        overlap = len(query_tokens_set & name_tokens)\n",
        "        prev_name = by_code.get(key, \"\")\n",
        "        prev_overlap = len(query_tokens_set & _tokenize_name(prev_name)) if prev_name else -1\n",
        "        if key not in by_code or overlap > prev_overlap or (overlap == prev_overlap and len(name) > len(prev_name)):\n",
        "            by_code[key] = name\n",
        "\n",
        "    candidates: List[Candidate] = []\n",
        "    for (eppocode, dtcode), fullname in by_code.items():\n",
        "        score, token_overlap, host_match = _score_candidate(eppocode, dtcode, fullname, norm)\n",
        "        candidates.append(\n",
        "            Candidate(\n",
        "                eppocode=eppocode,\n",
        "                dtcode=dtcode,\n",
        "                fullname=fullname,\n",
        "                score=score,\n",
        "                token_overlap=token_overlap,\n",
        "                host_match=host_match,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    candidates.sort(key=lambda c: c.score, reverse=True)\n",
        "    return candidates[:max_candidates]\n",
        "\n",
        "def select_best(candidates: List[Candidate], threshold: float) -> Optional[Candidate]:\n",
        "    if not candidates:\n",
        "        return None\n",
        "    best = candidates[0]\n",
        "    return best if best.score >= threshold else None\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3. EPPO API Retrieval\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def _load_cached(cache_dir: Path, eppocode: str, endpoint_suffix: str) -> Optional[Dict[str, Any]]:\n",
        "    cache_file = cache_dir / \"taxons\" / eppocode / f\"{endpoint_suffix}.json\"\n",
        "    if not cache_file.exists():\n",
        "        return None\n",
        "    try:\n",
        "        with open(cache_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _save_cached(cache_dir: Path, eppocode: str, endpoint_suffix: str, data: Any):\n",
        "    cache_file = cache_dir / \"taxons\" / eppocode / f\"{endpoint_suffix}.json\"\n",
        "    cache_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    try:\n",
        "        with open(cache_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(data, f)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def _get_eppo(eppocode: str, endpoint_suffix: str, api_key: str, base_url: str,\n",
        "              cache_dir: Optional[Path], use_cache: bool, max_retries: int = 3) -> Optional[Dict[str, Any]]:\n",
        "    if use_cache and cache_dir:\n",
        "        cached = _load_cached(cache_dir, eppocode, endpoint_suffix)\n",
        "        if cached is not None:\n",
        "            STATS.cache_hits += 1\n",
        "            return cached\n",
        "\n",
        "    url = f\"{base_url.rstrip('/')}/taxons/taxon/{eppocode}/{endpoint_suffix}\"\n",
        "    headers = {\"X-Api-Key\": api_key} if api_key else {}\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            import requests\n",
        "            STATS.cache_misses += 1\n",
        "            STATS.api_calls += 1\n",
        "            time.sleep(EPPO_RATE_LIMIT_DELAY)\n",
        "            resp = requests.get(url, headers=headers, timeout=30)\n",
        "            resp.raise_for_status()\n",
        "            data = resp.json()\n",
        "            if use_cache and cache_dir and data is not None:\n",
        "                _save_cached(cache_dir, eppocode, endpoint_suffix, data)\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(0.5 * (2 ** attempt))\n",
        "                continue\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def fetch_eppo_facts(eppocode: str, cache_dir: Optional[Path] = None, use_cache: bool = True) -> Dict[str, Any]:\n",
        "    cache_dir = cache_dir or EPPO_CACHE_DIR\n",
        "    overview = _get_eppo(eppocode, \"overview\", EPPO_API_KEY, EPPO_BASE_URL, cache_dir, use_cache)\n",
        "    names = _get_eppo(eppocode, \"names\", EPPO_API_KEY, EPPO_BASE_URL, cache_dir, use_cache)\n",
        "    hosts = _get_eppo(eppocode, \"hosts\", EPPO_API_KEY, EPPO_BASE_URL, cache_dir, use_cache)\n",
        "\n",
        "    return {\n",
        "        \"overview\": overview,\n",
        "        \"names\": names if isinstance(names, list) else [],\n",
        "        \"hosts\": hosts if isinstance(hosts, list) else [],\n",
        "    }\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4. Validation\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def _tokenize_text(text: str) -> Set[str]:\n",
        "    tokens = re.split(r\"[^\\w]+\", (text or \"\").lower())\n",
        "    return {t for t in tokens if len(t) >= 2}\n",
        "\n",
        "def _texts_from_facts(facts: Dict[str, Any]) -> List[str]:\n",
        "    texts: List[str] = []\n",
        "    overview = facts.get(\"overview\") or {}\n",
        "    if isinstance(overview, dict):\n",
        "        prefname = overview.get(\"prefname\")\n",
        "        if prefname:\n",
        "            texts.append(prefname)\n",
        "    for name_entry in facts.get(\"names\") or []:\n",
        "        if isinstance(name_entry, dict) and name_entry.get(\"fullname\"):\n",
        "            texts.append(name_entry[\"fullname\"])\n",
        "    for host_entry in facts.get(\"hosts\") or []:\n",
        "        if isinstance(host_entry, dict) and host_entry.get(\"prefname\"):\n",
        "            texts.append(host_entry[\"prefname\"])\n",
        "    return texts\n",
        "\n",
        "def validate_eppo_against_label(facts: Dict[str, Any], norm: NormalizedLabel, min_token_overlap: int = 1) -> bool:\n",
        "    if not facts or not norm.tokens:\n",
        "        return False\n",
        "\n",
        "    overview = facts.get(\"overview\")\n",
        "    if not overview or not isinstance(overview, dict):\n",
        "        return False\n",
        "\n",
        "    texts = _texts_from_facts(facts)\n",
        "    if not texts:\n",
        "        return False\n",
        "\n",
        "    label_tokens = set(norm.tokens)\n",
        "    combined = \" \".join(texts).lower()\n",
        "    combined_tokens = _tokenize_text(combined)\n",
        "    overlap = len(label_tokens & combined_tokens)\n",
        "    return overlap >= min_token_overlap\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5. Generation\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert plant pathologist and agricultural advisor. Your expertise includes disease diagnosis, treatment protocols, and integrated pest management.\n",
        "\n",
        "Your communication style:\n",
        "- Clear, concise, and action-oriented\n",
        "- Use simple language accessible to farmers and gardeners\n",
        "- Provide specific, practical advice (not vague generalities)\n",
        "- Include dosages, timing, and application methods when relevant\n",
        "- Acknowledge limitations or uncertainties honestly\n",
        "\n",
        "Your response structure:\n",
        "1. Confirmation: State clearly if prediction matches EPPO data (Yes/No + reasoning)\n",
        "2. Disease Overview: Explain cause, symptoms, and impact in 2-3 sentences\n",
        "3. Treatment: Provide 3-5 concrete actions with implementation details\n",
        "4. Prevention: List 3-5 preventive measures in priority order\n",
        "\n",
        "Avoid:\n",
        "- Generic advice like \"maintain good hygiene\" without specifics\n",
        "- Overly technical jargon without explanation\n",
        "- Unverified information not supported by EPPO data\n",
        "- Recommending products without active ingredients\"\"\"\n",
        "\n",
        "def _format_facts_for_prompt(facts: Dict[str, Any]) -> str:\n",
        "    parts = []\n",
        "    overview = facts.get(\"overview\") or {}\n",
        "    if isinstance(overview, dict):\n",
        "        prefname = overview.get(\"prefname\")\n",
        "        eppocode = overview.get(\"eppocode\")\n",
        "        if prefname:\n",
        "            parts.append(f\"Disease/Pest: {prefname}\")\n",
        "        if eppocode:\n",
        "            code = eppocode.get(\"eppocode\") if isinstance(eppocode, dict) else eppocode\n",
        "            if code:\n",
        "                parts.append(f\"EPPO Code: {code}\")\n",
        "\n",
        "    # Add common names for better understanding\n",
        "    common_names = []\n",
        "    for name_entry in facts.get(\"names\") or []:\n",
        "        if isinstance(name_entry, dict) and name_entry.get(\"fullname\"):\n",
        "            common_names.append(name_entry['fullname'])\n",
        "    if common_names:\n",
        "        parts.append(f\"Also known as: {', '.join(common_names[:5])}\")\n",
        "\n",
        "    # Add affected plants\n",
        "    hosts = []\n",
        "    for host_entry in facts.get(\"hosts\") or []:\n",
        "        if isinstance(host_entry, dict) and host_entry.get(\"prefname\"):\n",
        "            host_name = host_entry['prefname']\n",
        "            classification = host_entry.get(\"class_label\", \"\")\n",
        "            if classification:\n",
        "                hosts.append(f\"{host_name} ({classification})\")\n",
        "            else:\n",
        "                hosts.append(host_name)\n",
        "    if hosts:\n",
        "        parts.append(f\"Commonly affects: {', '.join(hosts[:10])}\")\n",
        "\n",
        "    return \"\\n\".join(parts) if parts else \"\"\n",
        "\n",
        "def generate_from_facts(cv_label: str, facts: Dict[str, Any]) -> str:\n",
        "    formatted = _format_facts_for_prompt(facts)\n",
        "    if not formatted.strip():\n",
        "        return \"I cannot provide a diagnosis: no EPPO-backed facts are available for this label.\"\n",
        "\n",
        "    if not GROQ_API_KEY:\n",
        "        return \"I cannot generate a response: Groq API key is not set.\"\n",
        "\n",
        "    try:\n",
        "        from groq import Groq\n",
        "        client = Groq(api_key=GROQ_API_KEY)\n",
        "        user_content = f'''Vision Model Prediction: \"{cv_label}\"\n",
        "\n",
        "=== EPPO DATABASE INFORMATION ===\n",
        "{formatted}\n",
        "\n",
        "=== YOUR TASK ===\n",
        "Analyze the prediction against EPPO data and provide a structured response:\n",
        "\n",
        "**1. CONFIRMATION**\n",
        "   - Does the prediction match the EPPO disease? (YES/NO)\n",
        "   - Explain your reasoning (2-3 sentences)\n",
        "   - If NO, specify what the prediction likely refers to\n",
        "\n",
        "**2. DISEASE OVERVIEW**\n",
        "   - Causative agent (pathogen type and scientific name)\n",
        "   - Primary symptoms (visible signs on plant)\n",
        "   - Economic/agricultural impact\n",
        "\n",
        "**3. TREATMENT OPTIONS** (in order of effectiveness)\n",
        "   - Option 1: [Method] - [Active ingredient/approach] - [Application timing]\n",
        "   - Option 2: [Method] - [Active ingredient/approach] - [Application timing]\n",
        "   - Option 3: [Method] - [Active ingredient/approach] - [Application timing]\n",
        "\n",
        "**4. PREVENTION STRATEGIES** (proactive measures)\n",
        "   - Priority 1: [Most critical preventive action]\n",
        "   - Priority 2: [Second most important]\n",
        "   - Priority 3: [Additional preventive measure]\n",
        "\n",
        "Keep each section concise (3-5 bullet points max). Focus on what farmers can DO, not just what to know.'''\n",
        "\n",
        "        STATS.groq_calls += 1\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": user_content},\n",
        "            ],\n",
        "            model=GROQ_MODEL,\n",
        "            max_completion_tokens=GROQ_MAX_TOKENS,\n",
        "            temperature=GROQ_TEMPERATURE,\n",
        "        )\n",
        "        content = response.choices[0].message.content if response.choices else None\n",
        "        return (content or \"\").strip() or \"I could not generate a response from the provided facts.\"\n",
        "    except Exception as e:\n",
        "        return f\"I cannot generate a response: {str(e)}\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 6. Pipeline\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "REFUSAL_NO_CANDIDATES = \"I cannot verify this diagnosis: no matching EPPO record was found for this label.\"\n",
        "REFUSAL_LOW_CONFIDENCE = \"I cannot verify this diagnosis: the match to EPPO data is too uncertain.\"\n",
        "REFUSAL_EPPO_FAILED = \"I cannot verify this diagnosis: EPPO data could not be retrieved.\"\n",
        "REFUSAL_VALIDATION_FAILED = \"I cannot verify this diagnosis: the retrieved EPPO data does not support this label.\"\n",
        "\n",
        "@dataclass\n",
        "class DiagnosisResult:\n",
        "    refused: bool\n",
        "    message: str\n",
        "    eppocode: Optional[str] = None\n",
        "    confidence: Optional[float] = None\n",
        "    debug_info: Optional[str] = None\n",
        "\n",
        "def diagnose(cv_label: str,\n",
        "             sqlite_path: Optional[Path] = None,\n",
        "             cache_dir: Optional[Path] = None,\n",
        "             confidence_threshold: float = CONFIDENCE_THRESHOLD,\n",
        "             debug: bool = False) -> DiagnosisResult:\n",
        "    sqlite_path = sqlite_path or SQLITE_PATH\n",
        "    cache_dir = cache_dir or EPPO_CACHE_DIR\n",
        "\n",
        "    norm = normalize_cv_label(cv_label)\n",
        "    if not norm.tokens:\n",
        "        return DiagnosisResult(refused=True, message=REFUSAL_NO_CANDIDATES)\n",
        "\n",
        "    candidates = query_candidates(sqlite_path, norm, max_candidates=30)\n",
        "\n",
        "    # Debug info\n",
        "    debug_info = None\n",
        "    if debug and candidates:\n",
        "        top_5 = candidates[:5]\n",
        "        debug_lines = [f\"\\nüîç Top candidates for '{cv_label}':\"]\n",
        "        for i, c in enumerate(top_5, 1):\n",
        "            debug_lines.append(f\"  {i}. {c.fullname} ({c.eppocode}) - Score: {c.score:.3f}\")\n",
        "        debug_info = \"\\n\".join(debug_lines)\n",
        "\n",
        "    best = select_best(candidates, confidence_threshold)\n",
        "    if best is None:\n",
        "        msg = REFUSAL_LOW_CONFIDENCE\n",
        "        if candidates:\n",
        "            msg += f\" (Top match: {candidates[0].fullname} with score {candidates[0].score:.3f}, threshold: {confidence_threshold})\"\n",
        "        return DiagnosisResult(\n",
        "            refused=True,\n",
        "            message=msg,\n",
        "            confidence=candidates[0].score if candidates else None,\n",
        "            debug_info=debug_info,\n",
        "        )\n",
        "\n",
        "    facts = fetch_eppo_facts(best.eppocode, cache_dir=cache_dir, use_cache=True)\n",
        "    if not facts.get(\"overview\"):\n",
        "        return DiagnosisResult(\n",
        "            refused=True,\n",
        "            message=REFUSAL_EPPO_FAILED,\n",
        "            eppocode=best.eppocode,\n",
        "            debug_info=debug_info,\n",
        "        )\n",
        "\n",
        "    if not validate_eppo_against_label(facts, norm, min_token_overlap=1):\n",
        "        return DiagnosisResult(\n",
        "            refused=True,\n",
        "            message=REFUSAL_VALIDATION_FAILED,\n",
        "            eppocode=best.eppocode,\n",
        "            debug_info=debug_info,\n",
        "        )\n",
        "\n",
        "    answer = generate_from_facts(cv_label, facts)\n",
        "    return DiagnosisResult(\n",
        "        refused=False,\n",
        "        message=answer,\n",
        "        eppocode=best.eppocode,\n",
        "        confidence=best.score,\n",
        "        debug_info=debug_info,\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ GreenRetrieval pipeline loaded successfully!\")\n",
        "print(f\"üìä Configuration: Confidence threshold = {CONFIDENCE_THRESHOLD}, Model = {GROQ_MODEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMSB6Bk5opLI"
      },
      "source": [
        "## Step 5: Run Plant Disease Diagnoses! üéâ\n",
        "\n",
        "Now let's diagnose some plant diseases. The pipeline will:\n",
        "1. Normalize the disease label\n",
        "2. Search the SQLite database for matching EPPO codes\n",
        "3. Retrieve verified data from EPPO API\n",
        "4. Validate and generate a factual response\n",
        "\n",
        "**Run the cell below to see it in action!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b523379b79541d98cd7254aef1dd12f",
            "814782b02ea94bafaa730daa546971a8",
            "0c324549629e41eabb61211ea66686ab",
            "484bc4730c5f4cc6afa295c0820d674c",
            "fd91e9b6201b4cda82246c8f9559a42b",
            "4922e3ee781642d78b45999448c7e687",
            "6873dd47317b4affa2e3d51d4e02a8b0",
            "f4f4628cf6a74feda92a7a83f4939a62",
            "df6c936933f349fba71a8a8a7f2fa80a",
            "705a1c9977f742d3b7c425903dabbb57",
            "506a0d06358e4e288f3766e233c226f2"
          ]
        },
        "id": "dhQ2Gp_DopLI",
        "outputId": "4f917727-1626-4a2b-a255-67b7514b2132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Database found at: /content/eppocodes_all.sqlite\n",
            "   Size: 47.3 MB\n",
            "   Active EPPO codes: 121,370\n",
            "\n",
            "================================================================================\n",
            "üåø Starting plant disease diagnosis...\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "üî¨ Diagnosing:   0%|                                 | 0/1 [00:00<?, ?disease/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b523379b79541d98cd7254aef1dd12f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ VERIFIED: Rice leaf blast\n",
            "--------------------------------------------------------------------------------\n",
            "**1. CONFIRMATION**  \n",
            "- **NO** ‚Äì The EPPO entry you were given describes *Alternaria padwickii* (leaf‚Äëspot/stack‚Äëburn of rice). ‚ÄúRice leaf blast‚Äù is caused by *Magnaporthe oryzae* (formerly *Pyricularia oryzae*), a different fungus.  \n",
            "- The prediction therefore refers to a different disease; the correct match for the EPPO data is **Alternaria leaf‚Äëspot (stack‚Äëburn)**, not leaf‚Äëblast.\n",
            "\n",
            "---\n",
            "\n",
            "**2. DISEASE OVERVIEW**  \n",
            "- **Causative agent:** Fungus *Alternaria padwickii* (Ascomycota).  \n",
            "- **Primary symptoms:** Small, water‚Äësoaked lesions that enlarge into brown‚Äëblack circular spots (5‚Äë10‚ÄØmm) with concentric rings; lesions may coalesce, giving a ‚Äústack‚Äëburn‚Äù appearance on leaves, sheaths, and panicles.  \n",
            "- **Impact:** Reduces photosynthetic area, lowers grain filling, and can cause 10‚Äë30‚ÄØ% yield loss in heavily infected fields; severe epidemics may lead to total crop failure under humid, warm conditions.\n",
            "\n",
            "---\n",
            "\n",
            "**3. TREATMENT OPTIONS** *(ranked by field efficacy)*  \n",
            "\n",
            "| # | Method | Active ingredient / approach | Application timing & dose* |\n",
            "|---|--------|-----------------------------|----------------------------|\n",
            "| 1 | Foliar fungicide spray | Triazole‚Äëbased (e.g., **tebuconazole** 0.1‚ÄØ%‚ÄØw/v) or strobilurin (e.g., **azoxystrobin** 0.15‚ÄØ%‚ÄØw/v) | First spray at tillering (when 5‚Äì6 leaves have unfolded); repeat every 10‚Äë14‚ÄØdays or after a rain event; total of 2‚Äì3 applications per season. |\n",
            "| 2 | Seed treatment | **Carbendazim** 2‚ÄØg‚ÄØkg‚Åª¬π seed or **thiram** 1‚ÄØg‚ÄØkg‚Åª¬π seed | Treat seed before sowing; follow label for mixing water volume; ensures protection during early seedling stage. |\n",
            "| 3 | Biological control | **Bacillus subtilis**‚Äëbased product (e.g., *B. subtilis* QST 713) | Apply as a foliar spray at tillering and again at panicle initiation; 2‚Äì3‚ÄØL‚ÄØha‚Åª¬π per application, 7‚Äëday interval. |\n",
            "\n",
            "\\*Dosages are typical recommendations; always adjust to local label rates and respect pre‚Äëharvest intervals.\n",
            "\n",
            "---\n",
            "\n",
            "**4. PREVENTION STRATEGIES**  \n",
            "\n",
            "1. **Use clean, certified seed** ‚Äì Plant seed that is certified disease‚Äëfree or pre‚Äëtreated with a systemic fungicide to eliminate seed‚Äëborne inoculum.  \n",
            "2. **Crop rotation & residue management** ‚Äì Rotate rice with non‚Äëhost crops (e.g., legumes) for ‚â•2‚ÄØyears and remove or deeply incorporate infected straw to reduce overwintering spores.  \n",
            "3. **Optimize field micro‚Äëclimate** ‚Äì Plant at recommended spacing, ensure good drainage, and avoid prolonged leaf wetness (e.g., avoid late‚Äëday irrigation); this limits the humid conditions that favor *A. padwickii* infection.  \n",
            "\n",
            "These actions together give the most reliable control of Alternaria leaf‚Äëspot in rice.\n",
            "\n",
            "üìã EPPO Code: ALTEPD\n",
            "üéØ Confidence: 131.67%\n",
            "\n",
            "‚ú® Diagnosis complete!\n",
            "\n",
            "================================================================================\n",
            "üìä PIPELINE SUMMARY STATISTICS\n",
            "================================================================================\n",
            "‚úÖ Verified: 1/1 (100.0%)\n",
            "üö´ Refused: 0/1 (0.0%)\n",
            "üéØ Average Confidence: 131.67%\n",
            "\n",
            "üíæ EPPO API Cache:\n",
            "   Hits: 0 (reused from disk)\n",
            "   Misses: 3 (fetched from API)\n",
            "   Total API Calls: 3\n",
            "\n",
            "ü§ñ Groq LLM Calls: 1\n",
            "================================================================================\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Run diagnoses for multiple plant diseases\n",
        "labels = [\n",
        "    \"Rice leaf blast\",\n",
        "    # \"Wheat leaf rust\",\n",
        "    # \"Potato leaf late blight\",\n",
        "]\n",
        "\n",
        "# Check database first\n",
        "import sqlite3\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Use the path from environment variable (set in Step 2)\n",
        "DB_PATH = Path(os.environ.get(\"EPPO_SQLITE_PATH\", \"/content/eppocodes_all.sqlite\"))\n",
        "\n",
        "if DB_PATH.exists():\n",
        "    print(f\"‚úÖ Database found at: {DB_PATH}\")\n",
        "    print(f\"   Size: {DB_PATH.stat().st_size / (1024*1024):.1f} MB\")\n",
        "\n",
        "    # Test query\n",
        "    conn = sqlite3.connect(str(DB_PATH))\n",
        "    cursor = conn.execute(\"SELECT COUNT(*) FROM t_codes WHERE status = 'A'\")\n",
        "    count = cursor.fetchone()[0]\n",
        "    print(f\"   Active EPPO codes: {count:,}\")\n",
        "    conn.close()\n",
        "else:\n",
        "    print(f\"‚ùå Database NOT found at: {DB_PATH}\")\n",
        "    print(\"   Please run Step 2 to load the database first!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üåø Starting plant disease diagnosis...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Reset statistics for this run\n",
        "STATS.reset()\n",
        "\n",
        "# Process with progress bar\n",
        "for label in tqdm(labels, desc=\"üî¨ Diagnosing\", unit=\"disease\", ncols=80):\n",
        "    result = diagnose(label)\n",
        "    STATS.add_diagnosis(result, label)\n",
        "    status = \"üö´ REFUSED\" if result.refused else \"‚úÖ VERIFIED\"\n",
        "\n",
        "    print(f\"\\n{status}: {label}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(result.message)\n",
        "\n",
        "    if result.eppocode:\n",
        "        print(f\"\\nüìã EPPO Code: {result.eppocode}\")\n",
        "    if result.confidence is not None:\n",
        "        print(f\"üéØ Confidence: {result.confidence:.2%}\")\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\n‚ú® Diagnosis complete!\")\n",
        "print(STATS.summary())\n",
        "print(\"=\" * 80)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zkhEW-MopLI"
      },
      "source": [
        "---\n",
        "\n",
        "## üìö How It Works\n",
        "\n",
        "**GreenRetrieval** is a retrieval-augmented generation (RAG) pipeline that ensures accurate, verified plant disease information:\n",
        "\n",
        "### Pipeline Steps:\n",
        "1. **Normalize**: Tokenize the disease label, remove generic terms (leaf, stem), preserve host + symptom\n",
        "2. **Retrieve**: Query local SQLite database for candidate EPPO codes using token matching\n",
        "3. **Rank**: Score candidates by token overlap, host match, and datatype preference\n",
        "4. **Refuse**: If no candidate exceeds confidence threshold, refuse (no guessing!)\n",
        "5. **Fetch**: Retrieve verified data from EPPO API (cached to respect rate limits)\n",
        "6. **Validate**: Ensure EPPO data actually supports the label semantics\n",
        "7. **Generate**: Use Groq LLM to create response ONLY from verified EPPO facts\n",
        "\n",
        "### Key Features:\n",
        "- ‚úÖ **No Hallucination**: Only uses verified EPPO database facts\n",
        "- ‚úÖ **Refusal-Aware**: Prefers refusing over guessing\n",
        "- ‚úÖ **Offline-First**: SQLite lookup before API calls\n",
        "- ‚úÖ **Cached**: EPPO API responses cached to `/content/.eppo_cache`\n",
        "- ‚úÖ **Transparent**: Shows EPPO codes and confidence scores\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Configuration\n",
        "\n",
        "All configuration is in the main code cell. Key parameters:\n",
        "\n",
        "```python\n",
        "CONFIDENCE_THRESHOLD = 0.45  # Minimum score to accept a match\n",
        "GROQ_MODEL = \"llama-3.3-70b-versatile\"  # LLM model\n",
        "GROQ_TEMPERATURE = 0.3  # Lower = more factual\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìñ Learn More\n",
        "\n",
        "- **EPPO Global Database**: https://gd.eppo.int\n",
        "- **Groq Console**: https://console.groq.com\n",
        "- **Project Repository**: [Your GitHub URL]\n",
        "\n",
        "---\n",
        "\n",
        "**Made with üå± by the GreenRetrieval team**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b523379b79541d98cd7254aef1dd12f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_814782b02ea94bafaa730daa546971a8",
              "IPY_MODEL_0c324549629e41eabb61211ea66686ab",
              "IPY_MODEL_484bc4730c5f4cc6afa295c0820d674c"
            ],
            "layout": "IPY_MODEL_fd91e9b6201b4cda82246c8f9559a42b"
          }
        },
        "814782b02ea94bafaa730daa546971a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4922e3ee781642d78b45999448c7e687",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6873dd47317b4affa2e3d51d4e02a8b0",
            "value": "üî¨‚ÄáDiagnosing:‚Äá100%"
          }
        },
        "0c324549629e41eabb61211ea66686ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4f4628cf6a74feda92a7a83f4939a62",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df6c936933f349fba71a8a8a7f2fa80a",
            "value": 1
          }
        },
        "484bc4730c5f4cc6afa295c0820d674c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_705a1c9977f742d3b7c425903dabbb57",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_506a0d06358e4e288f3766e233c226f2",
            "value": "‚Äá1/1‚Äá[00:06&lt;00:00,‚Äá‚Äá6.30s/disease]"
          }
        },
        "fd91e9b6201b4cda82246c8f9559a42b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80px"
          }
        },
        "4922e3ee781642d78b45999448c7e687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6873dd47317b4affa2e3d51d4e02a8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4f4628cf6a74feda92a7a83f4939a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6c936933f349fba71a8a8a7f2fa80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "705a1c9977f742d3b7c425903dabbb57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506a0d06358e4e288f3766e233c226f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}