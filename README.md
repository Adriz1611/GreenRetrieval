# ğŸŒ¿ GreenRetrieval

**Retrieval-Augmented Generation (RAG) system for plant disease diagnosis** â€” Combines EPPO Global Database taxonomic grounding with LLM-powered natural language synthesis to ensure factually accurate, hallucination-free plant pathology responses.

---

## ğŸ¯ Core Concept

Traditional LLMs hallucinate when queried about specialized domains like plant pathology. GreenRetrieval solves this via a **refusal-aware RAG pipeline**:

```
CV Label â†’ Normalize â†’ Retrieve â†’ Rank â†’ Validate â†’ Generate
   â†“           â†“          â†“         â†“        â†“          â†“
"Tomato   â†’ [tomato,  â†’ EPPO    â†’ Score  â†’ Check   â†’ Groq
 blight"     late,     SQLite     Î¸â‰¥0.3    overlap   LLM
             blight]    (121K)              Ïƒâ‰¥1       âœ“
```

**Refusal Threshold**: If confidence $\theta < 0.3$ or semantic validation fails, the system refuses to respond â€” prioritizing precision over recall.

---

## ğŸ“ Retrieval Scoring Function

Candidate EPPO codes are ranked using a composite score:

$$
S(c, q) = \min\left(\frac{|T_c \cap T_q|}{|T_q|} + \beta_h \cdot h(c, q) + \beta_\ell \cdot \ell(c, q) + \beta_d \cdot d(c), \, 1.5\right)
$$

Where:

- $T_c$: Token set of candidate name
- $T_q$: Token set of normalized query
- $h(c, q) \in \{0, 0.2\}$: Host match bonus (first token overlap)
- $\ell(c, q) \in [0, 0.3]$: Location term match ratio (leaf, stem, root, etc.)
- $d(c) \in \{0, 0.05, 0.15\}$: Datatype preference (GAF=primary pathogen, SFT=group)

**Design Insight**: The cap at 1.5 prevents exact-match overfitting while allowing multi-factor discrimination. Location terms receive high weight ($\beta_\ell = 0.3$) as "leaf rust" â‰  "stem rust" in phytopathology.

---

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ config.py          # Centralized constants (Î¸=0.3, Î² coefficients, model configs)
â”œâ”€â”€ normalization.py   # Token extraction: L â†’ {host, symptoms, locations}
â”œâ”€â”€ retrieval.py       # SQLite query + scoring: S(c, q) â†’ ranked candidates
â”œâ”€â”€ eppo_client.py     # API wrapper (rate limiting, exponential backoff, disk cache)
â”œâ”€â”€ validation.py      # Post-retrieval check: |T_eppo âˆ© T_query| â‰¥ Ïƒ
â”œâ”€â”€ generation.py      # Groq LLM (openai/gpt-oss-120b, 120B params, structured prompts)
â””â”€â”€ pipeline.py        # Orchestration: diagnose() with early-exit refusals
```

**Data Flow**:

1. **Offline**: 121,370 EPPO codes in `eppocodes_all.sqlite` (~50MB)
2. **Online**: API calls for `overview`, `names`, `hosts` (cached, 60 req/10s limit)
3. **LLM**: Structured 4-section response (Confirmation, Overview, Treatment, Prevention)

---

## ğŸš€ Usage

### Python Package

```python
from src import diagnose

result = diagnose("Rice leaf blast")

if not result.refused:
    print(result.message)          # LLM-generated diagnosis
    print(f"EPPO: {result.eppocode}")  # PYRIOR (Magnaporthe oryzae)
    print(f"Î¸ = {result.confidence:.2f}")  # 0.85
```

### Command Line

```bash
export EPPO_API_KEY="..." GROQ_API_KEY="..." EPPO_SQLITE_PATH="eppocodes_all.sqlite"
python run.py  # Batch diagnoses with progress bars + statistics
```

### Google Colab

Open `run_colab.ipynb` for interactive notebook with step-by-step cells.

---

## ğŸ§® Performance Characteristics

<table>
<tr>
<td width="50%">

### ğŸ“Š System Metrics

| Metric                      | Value                         |
| --------------------------- | ----------------------------- |
| ğŸ—„ï¸ **Database Size**        | **121,370** active EPPO codes |
| ğŸ¯ **Confidence Threshold** | $\theta = 0.3$                |
| ğŸ’¾ **Cache Hit Rate**       | **~80%** (typical)            |
| âš¡ **Avg. Latency**         | **2-3 seconds**               |

</td>
<td width="50%">

### ğŸ¤– LLM Configuration

| Parameter          | Value                 |
| ------------------ | --------------------- |
| ğŸ§  **Model**       | `openai/gpt-oss-120b` |
| ğŸš€ **Throughput**  | 500 tokens/second     |
| ğŸ“ˆ **Rate Limit**  | 250K TPM              |
| ğŸŒ¡ï¸ **Temperature** | 0.3 (factual)         |

</td>
</tr>
</table>

#### ğŸ“ Latency Breakdown

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Retrieval (SQLite)     â”‚ 0.5s â”‚ 20% â”‚
â”‚ LLM Generation (Groq)  â”‚ 1.5s â”‚ 60% â”‚
â”‚ API Calls (EPPO)       â”‚ 0.5s â”‚ 20% â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ“ Design Philosophy

> **High Precision over High Recall**  
> The system prioritizes **accuracy** by refusing uncertain matches ($\theta < 0.3$) rather than providing potentially incorrect diagnoses. This design choice is critical for agricultural decision-making where false positives can lead to:
>
> - âŒ Unnecessary pesticide application
> - ğŸ’° Economic losses from wrong treatments
> - ğŸŒ Environmental damage from improper interventions

**Coverage**: Full taxonomic coverage including fungi ğŸ„, bacteria ğŸ¦ , viruses ğŸ§¬, and pests ğŸ›

---

## ğŸ“Š Key Modules

### `normalization.py` â€” Semantic Decomposition

Extracts structured components from raw CV labels:

- **Tokens**: `["rice", "leaf", "blast"]` (length â‰¥ 2, generic terms filtered)
- **Hosts**: First token(s) matching known plant genera
- **Symptoms**: Remaining tokens (`["blight", "rust", "mosaic", ...]`)
- **Locations**: Preserved separately (`["leaf", "stem", ...]`) for scoring bonus

### `retrieval.py` â€” Candidate Ranking

- **SQL**: `LIKE` query across 121K codes (indexed, ~50ms)
- **Deduplication**: Best name per (EPPO code, datatype) tuple
- **Scoring**: $S(c, q)$ with multi-factor bonuses
- **Sorting**: Descending by score, top-$k$ retained ($k=50$ default)

### `eppo_client.py` â€” API Resilience

- **Rate Limiting**: 200ms delay between requests (< 60/10s EPPO limit)
- **Retries**: 3 attempts with exponential backoff (0.5s, 1s, 2s)
- **Caching**: JSON files in `.eppo_cache/taxons/{CODE}/` (persistent across runs)

### `generation.py` â€” Structured LLM Prompts

- **System Role**: Expert plant pathologist persona
- **User Prompt**: EPPO facts + 4-section template enforcement
- **Temperature**: $T = 0.3$ (low randomness for factual responses)
- **Max Tokens**: 1024 (sufficient for structured output)

---

## ğŸ”¬ Example Workflow

```python
# Input: CV model predicts "Wheat leaf rust"
label = "Wheat leaf rust"

# 1. Normalization
norm = normalize_cv_label(label)
# â†’ tokens: ["wheat", "leaf", "rust"]
# â†’ location_terms: ["leaf"]

# 2. Retrieval (SQLite query)
candidates = query_candidates(db, norm)
# â†’ Top match: "rust of wheat" (PUCCRT), S = 0.95

# 3. Selection (Î¸ = 0.3)
best = select_best(candidates, threshold=0.3)
# â†’ PUCCRT (Puccinia recondita f. sp. tritici)

# 4. Validation (EPPO API + token overlap)
facts = eppo_client.fetch_facts("PUCCRT")
valid = validate(facts, norm)  # Ïƒ = 1 token minimum
# â†’ True (overlap: "wheat", "rust")

# 5. Generation (Groq LLM)
response = generator.generate(label, facts)
# â†’ Structured 4-section markdown response

# Result
DiagnosisResult(
    refused=False,
    message="**1. CONFIRMATION**\nYES, the prediction matches...",
    eppocode="PUCCRT",
    confidence=0.95
)
```

---

## ğŸ“ File Structure

```
GreenRetrieval/
â”œâ”€â”€ src/                    # Modular Python package (8 modules)
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ normalization.py
â”‚   â”œâ”€â”€ retrieval.py
â”‚   â”œâ”€â”€ eppo_client.py
â”‚   â”œâ”€â”€ validation.py
â”‚   â”œâ”€â”€ generation.py
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ run.py                  # CLI entry point with progress tracking
â”œâ”€â”€ run_colab.ipynb         # Self-contained Colab notebook
â”œâ”€â”€ requirements.txt        # groq, requests, tqdm
â””â”€â”€ README.md              # You are here
```

---

## ğŸ”‘ Environment Variables

```bash
EPPO_API_KEY       # Get from https://data.eppo.int (free tier available)
GROQ_API_KEY       # Get from https://console.groq.com (free tier: 14,400 req/day)
EPPO_SQLITE_PATH   # Download from https://www.eppo.int/download (~50MB .zip)
EPPO_CACHE_DIR     # Optional: custom cache location (default: .eppo_cache)
```

---

## ğŸ“ References

- **EPPO Global Database**: Authoritative plant health data (200+ countries, 88K taxa)
- **Groq Inference**: LPU-accelerated LLM serving (500 tokens/sec)
- **RAG Pattern**: Combines retrieval precision with generative fluency

---

**Built with ğŸŒ± for reliable agricultural AI**
